# Kitchen Helper-AI - Rezept-Datenbank Konzept

## ğŸ¯ Ziel
Eine lokale Rezept-Datenbank, die mit Ollama zusammenarbeitet und die Rezeptgenerierung verbessert.

---

## ğŸ“Š DatenbankgrÃ¶ÃŸe & Umfang

### Option 1: Kompakte Starter-DB (Empfohlen)
**GrÃ¶ÃŸe:** ~50-100 MB
**Anzahl Rezepte:** 1.000-2.000
**Inhalt:**
- Deutsche Grundrezepte (500)
- Internationale Klassiker (300)
- Vegetarische/Vegane Rezepte (200)
- Schnelle Gerichte (<30min) (200)
- Desserts & Backwaren (150)

**Vorteile:**
- âœ… Schnelle Ladezeiten
- âœ… Geringer Speicherverbrauch
- âœ… Einfache Wartung
- âœ… Funktioniert gut mit Ollama (llama3.2:3b)

---

### Option 2: Erweiterte DB
**GrÃ¶ÃŸe:** ~500 MB - 1 GB
**Anzahl Rezepte:** 10.000-20.000
**Inhalt:**
- Komplette LÃ¤nderkÃ¼chen (20+ LÃ¤nder)
- Saisonale Rezepte
- DiÃ¤t-spezifische Varianten
- Professionelle Koch-Techniken

**Vorteile:**
- âœ… Mehr Vielfalt
- âœ… Bessere RezeptvorschlÃ¤ge
- âŒ Langsamere Suche ohne Index
- âŒ BenÃ¶tigt mehr RAM

---

## ğŸ—ï¸ Technische Architektur

### Datenbank-Format
```json
{
  "recipes": [
    {
      "id": "uuid-1234",
      "title": "Spaghetti Carbonara",
      "category": "italian",
      "difficulty": "easy",
      "cookTime": 20,
      "servings": 4,
      "ingredients": [
        {"name": "Spaghetti", "amount": 400, "unit": "g"},
        {"name": "Eier", "amount": 4, "unit": "stÃ¼ck"},
        {"name": "Parmesan", "amount": 100, "unit": "g"},
        {"name": "Pancetta", "amount": 150, "unit": "g"}
      ],
      "instructions": [
        "Spaghetti in Salzwasser kochen...",
        "Pancetta in Pfanne knusprig braten...",
        "Eier mit Parmesan verquirlen..."
      ],
      "tags": ["pasta", "schnell", "italienisch"],
      "nutrition": {
        "calories": 650,
        "protein": 28,
        "carbs": 75,
        "fat": 22
      },
      "allergens": ["gluten", "eier", "milch"]
    }
  ]
}
```

---

## ğŸ”— Integration mit Ollama

### Konzept 1: RAG (Retrieval-Augmented Generation)
**So funktioniert's:**
1. User fragt: "Was kann ich mit Tomaten, Mozzarella und Basilikum machen?"
2. Backend durchsucht Rezept-DB nach passenden Rezepten
3. Top 3 Rezepte werden an Ollama gegeben als Kontext
4. Ollama generiert personalisierte Antwort basierend auf echten Rezepten

**Beispiel-Prompt:**
```python
context = """
Gefundene Rezepte:
1. Caprese Salat (5min, einfach)
2. Tomate-Mozzarella Auflauf (30min, mittel)
3. Basilikum-Pesto mit Tomate (15min, einfach)
"""

prompt = f"""
Basierend auf diesen Rezepten:
{context}

Der Nutzer hat: Tomaten, Mozzarella, Basilikum
Erstelle ein detailliertes Rezept mit:
- Zutatenliste
- Schritt-fÃ¼r-Schritt Anleitung
- Kochzeit
- Schwierigkeitsgrad
"""
```

**Vorteil:**
- âœ… Ollama basiert auf echten, erprobten Rezepten
- âœ… Keine Halluzinationen (unrealistische Rezepte)
- âœ… Schnellere Generation (kleinerer Context)

---

### Konzept 2: Hybrid-Ansatz (Empfohlen!)
**Kombination aus DB + KI:**

**Schritt 1:** Suche in DB
```python
# Finde exakte Matches
exact_matches = db.search_by_ingredients(user_ingredients)

if len(exact_matches) > 0:
    # Zeige direkt Rezepte aus DB
    return exact_matches[0:3]
```

**Schritt 2:** KI-Generation mit DB-Kontext
```python
else:
    # Finde Ã¤hnliche Rezepte
    similar_recipes = db.search_similar(user_ingredients, limit=5)

    # Nutze Ã¤hnliche Rezepte als Inspiration fÃ¼r Ollama
    ollama_response = generate_recipe_with_context(
        ingredients=user_ingredients,
        inspiration=similar_recipes
    )
    return ollama_response
```

**Vorteil:**
- âœ… Schnell bei bekannten Kombinationen (direkt aus DB)
- âœ… Kreativ bei ungewÃ¶hnlichen Kombinationen (KI)
- âœ… Beste User Experience

---

## ğŸ“ Datei-Struktur

```
backend/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ recipes.db              # SQLite Datenbank (alternativ)
â”‚   â”œâ”€â”€ recipes.json            # JSON Format (einfacher)
â”‚   â””â”€â”€ embeddings/             # Vektor-Embeddings fÃ¼r Suche
â”‚       â””â”€â”€ recipe-vectors.npy
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ recipe_search.py        # Rezept-Suche Engine
â”‚   â”œâ”€â”€ recipe_rag.py           # RAG Integration
â”‚   â””â”€â”€ embedding_service.py    # Vektor-Suche
â””â”€â”€ routes/
    â””â”€â”€ recipes.py              # API Endpoints
```

---

## ğŸš€ Implementation Roadmap

### Phase 1: Basis-Datenbank (1-2 Tage)
- [ ] 500 Grund-Rezepte sammeln (deutsche KÃ¼che)
- [ ] JSON-Schema definieren
- [ ] SQLite Datenbank erstellen
- [ ] Einfache Suche implementieren (nach Zutaten)

### Phase 2: Ollama Integration (2-3 Tage)
- [ ] RAG-System implementieren
- [ ] Context-Builder fÃ¼r Ollama
- [ ] Hybrid-Ansatz (DB + KI)
- [ ] Caching fÃ¼r hÃ¤ufige Anfragen

### Phase 3: Erweiterte Features (optional)
- [ ] Vektor-Suche mit Embeddings
- [ ] Nutzer-Favoriten in DB speichern
- [ ] Rezept-Bewertungen
- [ ] Saisonale Empfehlungen

---

## ğŸ’¾ Speicheranforderungen

### Kompakt-DB (1000 Rezepte):
- JSON: ~50 MB
- SQLite: ~30 MB (komprimiert)
- Embeddings: ~20 MB
- **Gesamt:** ~100 MB

### Erweitert-DB (10.000 Rezepte):
- JSON: ~500 MB
- SQLite: ~300 MB
- Embeddings: ~200 MB
- **Gesamt:** ~1 GB

---

## ğŸ¯ Empfehlung fÃ¼r dich

**Start mit Kompakt-DB (500-1000 Rezepte):**
1. Schnell implementierbar
2. Funktioniert perfekt mit Ollama llama3.2:3b
3. Geringer RAM-Verbrauch (~100 MB zusÃ¤tzlich)
4. Kann spÃ¤ter erweitert werden

**Hybrid-Ansatz:**
- Exakte Matches aus DB (schnell)
- KI-Generation fÃ¼r neue Kombinationen (kreativ)
- Beste Balance zwischen Geschwindigkeit und FlexibilitÃ¤t

---

## ğŸ”§ Technische Details

### Datenbank-Wahl
**Option A: SQLite** (Empfohlen)
```python
# Vorteile:
- Eingebaut in Python
- Schnelle Suche mit Indizes
- Transaktionen
- Keine zusÃ¤tzliche Software
```

**Option B: JSON + In-Memory**
```python
# Vorteile:
- Einfacher zu editieren
- Schnell bei kleiner DB (<1000 Rezepte)
- Menschenlesbar
```

### Suche-Algorithmus
```python
def search_recipes(user_ingredients, db):
    # 1. Exakte Ãœbereinstimmung
    exact = db.find_recipes_with_all(user_ingredients)
    if exact:
        return exact

    # 2. Partial Match (mindestens 70% Zutaten)
    partial = db.find_recipes_with_most(user_ingredients, threshold=0.7)
    if partial:
        return partial

    # 3. Kategorie-basiert
    categories = infer_categories(user_ingredients)
    similar = db.find_by_category(categories)

    # 4. Ollama mit Kontext
    return ollama_generate_with_context(user_ingredients, similar)
```

---

## ğŸ“ˆ Performance-SchÃ¤tzung

**Ollama llama3.2:3b (auf deinem PC):**
- Ohne DB-Kontext: 10-15 Sekunden
- Mit DB-Kontext (RAG): 8-12 Sekunden (schneller!)
- Direkt aus DB: <1 Sekunde

**Vorteil DB + Ollama:**
- 20-30% schnellere Generierung
- Konsistentere Rezepte
- Weniger "Halluzinationen"

---

## ğŸ Bonus: Datenquellen

**Kostenlose Rezept-Datenbanken:**
1. **RecipeDB** (Open Source): 10.000+ Rezepte
2. **Food.com Dataset**: 180.000 Rezepte (Kaggle)
3. **Allrecipes Scraper**: Custom crawler
4. **Deutsche Rezepte**: Chefkoch.de API (falls verfÃ¼gbar)

**Lizenz-Hinweis:** Bei scraping immer Nutzungsbedingungen prÃ¼fen!

---

## ğŸ’¡ Fazit

**Empfohlener Ansatz:**
1. Start mit 1.000 Rezepten in SQLite
2. Hybrid-System (DB + Ollama)
3. RAG fÃ¼r bessere KI-Antworten
4. SpÃ¤ter auf 10.000+ erweitern

**GrÃ¶ÃŸe:** ~100 MB initial, ~1 GB maximal
**Kompatibel mit Ollama:** âœ… Ja, perfekt!
**Implementierungsaufwand:** 2-5 Tage
**Performance-Gewinn:** 20-30% schneller + bessere QualitÃ¤t

---

**Bereit fÃ¼r Implementation?** Lass mich wissen, ob du mit Phase 1 starten mÃ¶chtest! ğŸš€
